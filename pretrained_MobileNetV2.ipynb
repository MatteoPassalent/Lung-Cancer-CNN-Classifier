{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e91ef0-6578-4196-90c7-78116632cf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras import models, layers, optimizers, regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb92c06-11c6-43d4-8272-2061e97616b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"/mnt/c/LungCancerCT/CTscans\"\n",
    "data_generator = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      validation_split=0.15,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "train_generator = data_generator.flow_from_directory(train_path,\n",
    "                                                    class_mode=\"binary\",\n",
    "                                                    subset=\"training\",\n",
    "                                                    target_size=(224, 224),)\n",
    "validation_generator = data_generator.flow_from_directory(train_path,\n",
    "                                                    class_mode=\"binary\",\n",
    "                                                    subset=\"validation\",\n",
    "                                                    target_size=(224, 224),)\n",
    "conv_base = MobileNetV2(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(224, 224, 3))\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "conv_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0160af6e-b3bf-4390-b76c-ef03c3766fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(learning_rate=2e-5),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(train_generator,\n",
    "                    epochs=10,\n",
    "                    validation_data=validation_generator,\n",
    "                    callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb093f71-da83-4b25-bdca-4b025e6236b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = True\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'block_16_expand':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(learning_rate=1e-5),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "new_history = model.fit(train_generator,\n",
    "                    epochs=20,\n",
    "                    validation_data=validation_generator,\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a05d26-9192-49b1-923e-d87016ff8229",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "average_train_accuracy = sum(train_accuracy) / len(train_accuracy)\n",
    "average_val_accuracy = sum(val_accuracy) / len(val_accuracy)\n",
    "accuracy_difference = average_train_accuracy - average_val_accuracy\n",
    "\n",
    "average_train_loss = sum(train_loss) / len(train_loss)\n",
    "average_val_loss = sum(val_loss) / len(val_loss)\n",
    "\n",
    "print(f\"Average Training Accuracy: {average_train_accuracy:.4f}\")\n",
    "print(f\"Average Validation Accuracy: {average_val_accuracy:.4f}\")\n",
    "print(f\"Difference: {accuracy_difference:.4f}\")\n",
    "\n",
    "print(f\"Average Training loss: {average_train_loss:.4f}\")\n",
    "print(f\"Average Validation loss: {average_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d784b079-ccf6-48a0-a03c-432ce1459ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history['accuracy'].extend(new_history.history['accuracy'])\n",
    "history.history['val_accuracy'].extend(new_history.history['val_accuracy'])\n",
    "history.history['loss'].extend(new_history.history['loss'])\n",
    "history.history['val_loss'].extend(new_history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf209182-e0da-4c76-97c9-b7d9d5aab9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_curve(points, factor=0.8):\n",
    "  smoothed_points = []\n",
    "  for point in points:\n",
    "    if smoothed_points:\n",
    "      previous = smoothed_points[-1]\n",
    "      smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "    else:\n",
    "      smoothed_points.append(point)\n",
    "  return smoothed_points\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs,\n",
    "         smooth_curve(acc), 'bo', label='Smoothed training acc')\n",
    "plt.plot(epochs,\n",
    "         smooth_curve(val_acc), 'b', label='Smoothed validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs,\n",
    "         smooth_curve(loss), 'bo', label='Smoothed training loss')\n",
    "plt.plot(epochs,\n",
    "         smooth_curve(val_loss), 'b', label='Smoothed validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d7bc42-ef54-4ca9-b5b8-2cb57aa9f758",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"/mnt/c/LungCancerCT/final_test_images\"\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_path,\n",
    "        target_size=(224, 224),\n",
    "        class_mode='binary')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print('test acc:', test_acc)\n",
    "\n",
    "model.save('MobileNetV2.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11014dae-0462-48c8-871a-c1e638a76d56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
