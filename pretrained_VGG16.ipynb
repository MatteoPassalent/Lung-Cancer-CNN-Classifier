{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4ce01f-3a78-4a07-abf2-ae64c04fc98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras import models, layers, optimizers, regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f525192c-2f4f-46d7-b585-68b08f5794e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_path = \"/mnt/c/LungCancerCT/CTscans\"\n",
    "data_generator = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      validation_split=0.15,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "train_generator = data_generator.flow_from_directory(train_path,\n",
    "                                                    class_mode=\"binary\",\n",
    "                                                    subset=\"training\",)\n",
    "validation_generator = data_generator.flow_from_directory(train_path,\n",
    "                                                    class_mode=\"binary\",\n",
    "                                                    subset=\"validation\",)\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(256, 256, 3))\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "conv_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d937f4eb-969f-484f-bc3b-ba772d119579",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(learning_rate=2e-5), #read online works better with set rate than adam\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(train_generator,\n",
    "                    epochs=25,\n",
    "                    validation_data=validation_generator,\n",
    "                    callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70132951-6603-4042-bc8f-27fecadb9973",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = True\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'block5_conv1':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(learning_rate=1e-5),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "new_history = model.fit(train_generator,\n",
    "                    epochs=50,\n",
    "                    validation_data=validation_generator,\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1714814c-18e2-4a93-9dc3-57ce29bcfdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "average_train_accuracy = sum(train_accuracy) / len(train_accuracy)\n",
    "average_val_accuracy = sum(val_accuracy) / len(val_accuracy)\n",
    "accuracy_difference = average_train_accuracy - average_val_accuracy\n",
    "\n",
    "average_train_loss = sum(train_loss) / len(train_loss)\n",
    "average_val_loss = sum(val_loss) / len(val_loss)\n",
    "\n",
    "print(f\"Average Training Accuracy: {average_train_accuracy:.4f}\")\n",
    "print(f\"Average Validation Accuracy: {average_val_accuracy:.4f}\")\n",
    "print(f\"Difference: {accuracy_difference:.4f}\")\n",
    "\n",
    "print(f\"Average Training loss: {average_train_loss:.4f}\")\n",
    "print(f\"Average Validation loss: {average_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a88194-da71-43fd-a3de-7084342d0b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history['accuracy'].extend(new_history.history['accuracy'])\n",
    "history.history['val_accuracy'].extend(new_history.history['val_accuracy'])\n",
    "history.history['loss'].extend(new_history.history['loss'])\n",
    "history.history['val_loss'].extend(new_history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48323d0b-cf0f-47b9-b511-cc71ac18d28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_curve(points, factor=0.8):\n",
    "  smoothed_points = []\n",
    "  for point in points:\n",
    "    if smoothed_points:\n",
    "      previous = smoothed_points[-1]\n",
    "      smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "    else:\n",
    "      smoothed_points.append(point)\n",
    "  return smoothed_points\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs,\n",
    "         smooth_curve(acc), 'bo', label='Smoothed training acc')\n",
    "plt.plot(epochs,\n",
    "         smooth_curve(val_acc), 'b', label='Smoothed validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs,\n",
    "         smooth_curve(loss), 'bo', label='Smoothed training loss')\n",
    "plt.plot(epochs,\n",
    "         smooth_curve(val_loss), 'b', label='Smoothed validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f94201-2e07-4a70-a5a7-21f9a3dc42f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"/mnt/c/LungCancerCT/final_test_images\"\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_path,\n",
    "        target_size=(256, 256),\n",
    "        class_mode='binary')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print('test acc:', test_acc)\n",
    "\n",
    "model.save('VGG16.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed02d0e7-cc6e-439e-b6b9-0dadd442cc61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
